{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true,
      "collapsed_sections": [
        "5lsvqIKsWblI",
        "d4hkpXXXMuvn",
        "HBbzbhJCM-z8",
        "W6AB8Aj2M_4W",
        "lgCNT7GwNBOr"
      ],
      "authorship_tag": "ABX9TyNere0osgY9J+C6WNQE4yyt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duchaba/book_python_genAI_genZ/blob/master/Chapter_7_Duc_Python_GenAI_GenZ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üåª Welcome Reader and Coder\n",
        "---\n",
        "\n",
        "- Let's Rock and Roll"
      ],
      "metadata": {
        "id": "3WnEac7Fwdgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Print Piggy (to see if I am alive)\n",
        "\n",
        "fname = 'Piggy'\n",
        "print(f'Welcome reader and coder: {fname}.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJVD8p_vPR7D",
        "outputId": "aeb4bb89-f34c-4ec3-a678-0ccb3fec12e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome reader and coder: Piggy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìó Book Title ‚Äì Python Simplified with Generative AI\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Introduction:\n",
        "\n",
        "In the bustling corridors of the university, amidst the chatter of new ideas and the rustle of\n",
        "textbooks, there is a common thread of a challenge looming before us. As college students, we\n",
        "faced the daunting task of navigating the digital landscape, such as learning about complex\n",
        "programming code, internalizing AI paradigms, and expanding our personal growth.\n",
        "\n",
        "However, most existing books fail to connect with us. The books seem distant because they\n",
        "were authored by academics and industry professionals who disconnected from the\n",
        "challenges of the new Generative Artificial Intelligence (GenAI) era in education. Hence, we\n",
        "propose to craft this book, written by college students for college students, with a coauthor\n",
        "who is a renowned AI leader and an author of the book ‚ÄúData Augmentation with Python.‚Äù\n",
        "\n",
        "We are a generation that thrives on immediacy and experiential learning. The GenZ, our lot,\n",
        "don‚Äôt just learn; we ‚Äòdo,‚Äô we ‚Äòexperience.‚Äô And that‚Äôs where GenAI, such as GPT-4‚Äôs Copilot,\n",
        "Meta Code Llama, or Google Gemini, emerges as a beacon. Drawing inspiration from the\n",
        "growth of AI in modern learning, GenAI is your personalized coach or a teaching assistant\n",
        "always by your side.\n",
        "\n",
        "The proposed book's core learning experience will be a narrative of a human and an AI\n",
        "working together to learn from a series of short, interactive projects on Python Jupyter\n",
        "Notebooks (Notebooks). Along the way, the reader will learn how to write code in Python and\n",
        "practice it on a copy of the Notebook. The lessons are functional projects recognizable to\n",
        "GenZ as everyday activities.\n",
        "\n",
        "In contrast, many Python books prioritize comprehending data structures, algorithms, and\n",
        "complex syntax before implementing them. Furthermore, the outdated teaching approach\n",
        "relies solely on one narrative and doesn't allow students to independently investigate and\n",
        "challenge the lessons.\n",
        "\n",
        "The play-first method increases confidence and connects theory, GenAI, and real-world\n",
        "application. It aligns with GenZ's preference for experiential learning, i.e., learning by doing.\n",
        "The readers will remember that this isn‚Äôt just another Python book. Instead, it is a unique\n",
        "journey where a fellow human and digital GenAI will accompany you every step. They will\n",
        "teach, demonstrate, guide, assist, and motivate as you learn Python coding. Furthermore, the\n",
        "readers can adapt the learning journey to various other college topics, including but not\n",
        "limited to science, history, art, and communication. Welcome to a learning experience\n",
        "tailored for our generation by one of our own."
      ],
      "metadata": {
        "id": "PW2-o66xPSlN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üçé Welcome to Chapter 7: HuggingFace Deployment\n",
        "---\n",
        "\n",
        "## Structure\n",
        "\n",
        "Topics:\n",
        "1. Understand The Dynamic Trio\n",
        "\n",
        "1. Deployment\n",
        "1. Magnify HuggingFace\n",
        "1. Design with Gradio\n",
        "2. The Joy of Launch\n",
        "\n"
      ],
      "metadata": {
        "id": "xmcx9tkOSqK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üçÄ Author: Duc\n",
        "---\n"
      ],
      "metadata": {
        "id": "DHGKa52qwsp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ Topic #1: Understand The Dynamic Trio"
      ],
      "metadata": {
        "id": "5lsvqIKsWblI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NO coding"
      ],
      "metadata": {
        "id": "QOW1B1euMrPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ Topic #2: Deployment"
      ],
      "metadata": {
        "id": "d4hkpXXXMuvn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Smoke test: quick sample"
      ],
      "metadata": {
        "id": "jCW-T1uBkGVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: install and import gradio\n",
        "\n",
        "!pip install gradio\n",
        "import gradio"
      ],
      "metadata": {
        "id": "-SrU_QInks1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print gradio version\n",
        "\n",
        "print(f'Graido version: {gradio.__version__}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkZ1tmzvrkf_",
        "outputId": "1a934048-d48a-4f43-917d-6a266c7aa552"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graido version: 4.38.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile book_python_genai/app.py\n",
        "# prompt: Using Gradio to write a simple calculator app\n",
        "\n",
        "import gradio\n",
        "def calculator(num1, operation, num2):\n",
        "  if operation == \"add\":\n",
        "    return num1 + num2\n",
        "  elif operation == \"subtract\":\n",
        "    return num1 - num2\n",
        "  elif operation == \"multiply\":\n",
        "    return num1 * num2\n",
        "  elif operation == \"divide\":\n",
        "    return num1 / num2\n",
        "\n",
        "demo = gradio.Interface(\n",
        "    fn=calculator,\n",
        "    inputs=[\"number\", gradio.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\n",
        "    outputs=\"number\")\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "aM8rJK0RMuv1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "outputId": "0e15ed05-1948-4816-aa38-196c233dadc6"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://d561d3606790b25232.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d561d3606790b25232.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy it"
      ],
      "metadata": {
        "id": "VoVjXGsv4Mdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Write a code on deploy the calculator app on HuggingFace\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "PBGyo7HRMuv2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "outputId": "42c5c7cf-e574-4dfb-c8bd-2582bb893558"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
            "----\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://17984e44862750dba4.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://17984e44862750dba4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ Topic #3: Magnify HuggingFace"
      ],
      "metadata": {
        "id": "HBbzbhJCM-z8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " - Creat the HuggingFace space\n",
        "\n",
        " - See the result"
      ],
      "metadata": {
        "id": "xCSiNi9SodOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone"
      ],
      "metadata": {
        "id": "7Oddvcgc438U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: git clone the https://huggingface.co/spaces/duchaba/book_python_genai\n",
        "\n",
        "fname = 'https://huggingface.co/spaces/duchaba/book_python_genai'\n",
        "!git clone {fname}"
      ],
      "metadata": {
        "id": "0dSvqMO4M-0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef88136-619d-4d30-a3f1-2234eae259a9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'book_python_genai'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects:  25% (1/4)\rUnpacking objects:  50% (2/4)\rUnpacking objects:  75% (3/4)\rUnpacking objects: 100% (4/4)\rUnpacking objects: 100% (4/4), 1.28 KiB | 1.28 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# smoke test: check out the files\n",
        "\n",
        "fname = 'book_python_genai'\n",
        "!ls -Fa {fname}"
      ],
      "metadata": {
        "id": "MuDyNPwxM-0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e7b7fb1-5369-41ea-f509-92af86436df2"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./  ../  .git/\t.gitattributes\tREADME.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: display file README.md\n",
        "\n",
        "!cat book_python_genai/README.md"
      ],
      "metadata": {
        "id": "uDsGQJ7xM-0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1935832a-267f-4399-f379-e6d8f1e39d9d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "title: Book Python Genai\n",
            "emoji: üåñ\n",
            "colorFrom: green\n",
            "colorTo: red\n",
            "sdk: gradio\n",
            "sdk_version: 4.38.1\n",
            "app_file: app.py\n",
            "pinned: false\n",
            "license: gpl-3.0\n",
            "---\n",
            "\n",
            "Check out the configuration reference at https://huggingface.co/docs/hub/spaces-config-reference\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create requirments.txt file"
      ],
      "metadata": {
        "id": "vC9YM4Lf46_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create an array with value \"gradio, numpy\" name requirement\n",
        "\n",
        "requirements = [\"gradio\", \"numpy\"]"
      ],
      "metadata": {
        "id": "9dEmXIgVqgZR"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Write requirements var into a file called requirements.txt in directory book_python_genai\n",
        "\n",
        "with open('book_python_genai/requirements.txt', 'w') as f:\n",
        "  for line in requirements:\n",
        "    f.write(f\"{line}\\n\")"
      ],
      "metadata": {
        "id": "q3ExfDSnqgc0"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print file book_python_genai/requirements.txt\n",
        "\n",
        "!cat book_python_genai/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZHhhui_qggf",
        "outputId": "1faa24e9-9029-4489-fe35-5961d18619c3"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gradio\n",
            "numpy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write app.py file"
      ],
      "metadata": {
        "id": "K1drZx8-5KYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# see above %%write"
      ],
      "metadata": {
        "id": "r73PxTEw5N16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print the app.py file in directory book_python_genai\n",
        "\n",
        "!cat book_python_genai/app.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGT-i9Ns5vLq",
        "outputId": "969cda17-52ae-4bd3-df59-d9c7468da7d1"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# prompt: Using Gradio to write a simple calculator app\n",
            "\n",
            "import gradio\n",
            "def calculator(num1, operation, num2):\n",
            "  if operation == \"add\":\n",
            "    return num1 + num2\n",
            "  elif operation == \"subtract\":\n",
            "    return num1 - num2\n",
            "  elif operation == \"multiply\":\n",
            "    return num1 * num2\n",
            "  elif operation == \"divide\":\n",
            "    return num1 / num2\n",
            "\n",
            "demo = gradio.Interface(\n",
            "    fn=calculator,\n",
            "    inputs=[\"number\", gradio.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\n",
            "    outputs=\"number\")\n",
            "\n",
            "demo.launch()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: list file in directory book_python_genai\n",
        "\n",
        "!ls -Fa book_python_genai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uME6HVXqgmw",
        "outputId": "002582bb-e0e4-4b8b-a1c0-cf3e303228b2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./  ../  app.py  .git/\t.gitattributes\tREADME.md  requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Git access"
      ],
      "metadata": {
        "id": "D_-ypQ_u5UJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: add token \"my_token1\" to OS variable\n",
        "\n",
        "import os\n",
        "# os.environ[\"hf_token\"] = \"my_token1\"\n",
        "# os.environ[\"hf_user_name\"] = \"my_user_name\"\n",
        "# os.environ[\"hf_email\"] = \"my_email\"\n",
        "os.environ[\"hf_token\"] = \"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\"\n",
        "os.environ[\"hf_user_name\"] = \"duchaba\"\n",
        "os.environ[\"hf_email\"] = \"duc.haba@gmail.com\""
      ],
      "metadata": {
        "id": "RaE_iueIxdnw"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: add git user email duc.haba@gmail.com and user name duchaba\n",
        "\n",
        "fname = os.environ.get('hf_user_name')\n",
        "femail = os.environ.get('hf_email')\n",
        "!git config --global user.email {femail}\n",
        "!git config --global user.name {fname}\n"
      ],
      "metadata": {
        "id": "oU0oLES8wkYc"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: export HUGGINGFACE_TOKEN with value from os environment hf_token\n",
        "\n",
        "ftoken = os.environ.get('hf_token')\n",
        "!export HUGGINGFACE_TOKEN={ftoken}"
      ],
      "metadata": {
        "id": "Iiq0ClODyDbZ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: change directory to book_python_genai using os\n",
        "\n",
        "os.chdir('book_python_genai')"
      ],
      "metadata": {
        "id": "dZhFuYTFyw3i"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: push the code in directory book_python_genai to git https://huggingface.co/spaces/duchaba/book_python_genai using jupyter notebook\n",
        "\n",
        "ftoken = os.environ.get('hf_token')\n",
        "!git add .\n",
        "!git commit -m \"first commit\"\n",
        "!git push https://duchaba:{ftoken}@huggingface.co/spaces/duchaba/book_python_genai main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFowJkYevdjU",
        "outputId": "92358c5f-9389-403b-a08c-50c64b6426d4"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[main 40ef470] first commit\n",
            " 2 files changed, 21 insertions(+)\n",
            " create mode 100644 app.py\n",
            " create mode 100644 requirements.txt\n",
            "Enumerating objects: 5, done.\n",
            "Counting objects: 100% (5/5), done.\n",
            "Delta compression using up to 8 threads\n",
            "Compressing objects: 100% (3/3), done.\n",
            "Writing objects: 100% (4/4), 601 bytes | 601.00 KiB/s, done.\n",
            "Total 4 (delta 0), reused 0 (delta 0), pack-reused 0\n",
            "To https://huggingface.co/spaces/duchaba/book_python_genai\n",
            "   488b071..40ef470  main -> main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QA It"
      ],
      "metadata": {
        "id": "U2FyLkss-vYr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "22rWd4cqvdmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PMQfFXiK_7Zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bas command"
      ],
      "metadata": {
        "id": "pKGBBifu_78g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cfile = \"\"\"https://duchaba-book-python-genai.hf.space/call/predict -s -H \"Content-Type: application/json\" -d '{\n",
        "#   \"data\": [\n",
        "#     3,\n",
        "#     \"add\",\n",
        "#     3\n",
        "# ]}' \\\n",
        "#   | awk -F'\"' '{ print $4}'  \\\n",
        "#   | read EVENT_ID; curl -N https://duchaba-book-python-genai.hf.space/call/predict/$EVENT_ID\n",
        "# \"\"\"\n",
        "cfile = \"\"\"https://duchaba-book-python-genai.hf.space/call/predict -s -H \"Content-Type: application/json\" -d '{\n",
        "  \"data\": [\n",
        "    3,\n",
        "    \"add\",\n",
        "    3\n",
        "]}'\n",
        "\"\"\"\n",
        "!curl -X POST {cfile}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N_z1XRavdqO",
        "outputId": "f90a9e90-2361-4b33-c9f2-9a6eebe11af2"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"event_id\":\"c6f9ea59e6ff4ed0a8f8778e790b7097\"}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fid = 'c6f9ea59e6ff4ed0a8f8778e790b7097'\n",
        "!curl -N https://duchaba-book-python-genai.hf.space/call/predict/{fid}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXuVWqsI_gpl",
        "outputId": "9d758998-64ae-4800-ec48-01143b0188d1"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "event: complete\n",
            "data: [6]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python"
      ],
      "metadata": {
        "id": "ylk3CyFaABPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio_client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zcqg3z6vd19",
        "outputId": "f40e769b-dbb4-4cf8-8570-201fd7d5bdc3"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio_client in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio_client) (2023.6.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio_client) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio_client) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio_client) (24.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio_client) (4.12.2)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio_client) (11.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio_client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio_client) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio_client) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio_client) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio_client) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio_client) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (3.15.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio_client) (4.66.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio_client) (1.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio_client) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio_client) (2.0.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt: (Code from HuggingFace API)\n",
        "import gradio_client\n",
        "\n",
        "client = gradio_client. Client(\"duchaba/book_python_genai\")\n",
        "result = client.predict(\n",
        "\t\tnum1=20,\n",
        "\t\toperation=\"add\",\n",
        "\t\tnum2=3,\n",
        "\t\tapi_name=\"/predict\"\n",
        ")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkXP5cqfAtZq",
        "outputId": "dbad8f1a-832a-4242-a2ea-ffe3e3645715"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded as API: https://duchaba-book-python-genai.hf.space ‚úî\n",
            "23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ Topic #4: Design with Gradio"
      ],
      "metadata": {
        "id": "W6AB8Aj2M_4W"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iPzGzRh8M_4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7CcBnur9M_4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xk0R5urYM_4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ñ Topic #5: The Joy of Launch"
      ],
      "metadata": {
        "id": "lgCNT7GwNBOr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xv8t_x2MNBOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-by7cUJvNBOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fPTDXQujNBOt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}